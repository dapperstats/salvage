## Data Conversion

### Remote `.accdb` to local `.csv`s `bash` script

The main conversion is from the `.accdb` file on the remote [ftp](ftp://ftp.dfg.ca.gov/salvage/) to a local set of `.csv` files named by the tables in the database. 
We accomplish this through a [`bash`](https://www.gnu.org/software/bash/) script [`remote_mdb_to_local_csvs.bash`](https://github.com/dapperstats/salvage/blob/master/scripts/remote_mdb_to_local_csvs.bash).
The script requires three libraries be downloaded: `curl` (for downloading the `.accdb`), `mdbtools` (top-level functions for database interfacing and conversion), and `unixodbc` (database engines). 
Working in a `bash`-friendly terminal (using `sudo` if needed), first install the packages, then run the bash script:

```
sudo apt-get update && apt-get install -y \
       curl \
       mdbtools \
       unixodbc-dev
sudo bash scripts/remote_mdb_to_local_csvs.bash
```

This will produce a `/data` directory (if missing) and populate it with a local version of the `.accdb` and the `.csv`s, which are cross-platform compatable and relatively lightweight data files.

### Local `.csv`s to `R` `list` object `R` script

An additional conversion makes the data available in [`R`](https://www.r-project.org/) as a `list` of `data.frames` that is directly analagous to the `.accdb` database of tables.
Within an instance of `R`, simply source the functions script and read in the database:
```
source("scripts/r_functions.R")
database <- read_database()
```
The resulting `database` object is a named `list` of the database's tables, ready for analyses.

### Stable Conversion via `Docker`

To provide a simple set of commands that will reliably produce up-to-date versions of the data (as `.csv`s and an `R` `list`) from the `.accdb`, we provide a [`Docker`](https://www.docker.com) [software container](https://www.docker.com/resources/what-container).
The [salvage image](https://hub.docker.com/u/dapperstats/salvage) is freely available on [Docker Hub](https://hub.docker.com/).

The [`Dockerfile`](https://github.com/dapperstats/salvage/blob/master/Dockerfile) shows how the salvage image is built on top of the [`r-base`](https://hub.docker.com/_/r-base) image by running the same library installations as above, copying the `/scripts` directory, and setting environment variables. 
When a container is then constructed from the image, the final command to run `scripts/container_start.bash` with a set of arguments is executed.
[`container_start.bash`](https://github.com/dapperstats/salvage/blob/master/scripts/container_start.bash.bash) runs `remote_mdb_to_local_csvs.bash` and plunks the user into an interactive `R` session, where `r_functions.R` has been sourced and `database` exists as a `list` generated by `read_database()`.
Because the final command of the `Dockerfile` is [triggered by the building of a container](https://docs.docker.com/storage/storagedriver/) **every container is endowed with the most up-to-date data at the time of its construction**.
This allows us to write code that does not need to change, only be recalled (e.g., via `cron` or a user request) to update the data.

To use the current image to generate an up-to-date container
1. (If needed) [Install Docker](https://docs.docker.com/get-docker/)
   * Specific instructions vary depending on OS
2. Download the image
   * `sudo docker pull dapperstats/salvage`
3. Run the container
   * `sudo docker container run -ti --name salvage dapperstats/salvage`
