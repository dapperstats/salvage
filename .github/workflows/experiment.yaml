# Run the cron job without containers
name: cron_experiment

on:
  pull_request:
    branches:
      - main
  schedule:
    - cron: '0 0 * * *' # daily



jobs:
  salvage_pipeline:
    name: experimenting 
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install system dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install mdbtools
          sudo apt-get install unixodbc-dev
      - name: create directories
        run: |
          mkdir "data/Salvage_data_FTP" -p
      - name: wget the db
        run: |
          wget "https://filelib.wildlife.ca.gov/Public/salvage/Salvage_data_FTP.accdb" -nv -q -O "data/local.accdb" --show-progress
      - name: convert the db
        run: |
          echo "Converting to csvs..."
          mdb-tables -1 "data/local.accdb" | xargs -L1 -d '\n' -I{} bash -c 'mdb-export "$1" "$2" > "$3"' -- "data/local.accdb" {} "data/Salvage_data_FTP"/{}.csv
          ls data/Salvage_data_FTP